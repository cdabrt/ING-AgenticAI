# Copy to .env and replace placeholders before running the pipeline.

# Gemini API key (required).
GEMINI_API_KEY=your-gemini-key

# Optional: forwarded to LangChain if you prefer to keep both keys explicit.
GOOGLE_API_KEY=${GEMINI_API_KEY}

# LLM provider selection: gemini (default) or openrouter.
LLM_PROVIDER=gemini

# OpenRouter API key (required if LLM_PROVIDER=openrouter).
OPENROUTER_API_KEY=your-openrouter-key
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Model overrides (optional; defaults shown here).
QUERY_MODEL_NAME=gemini-2.5-flash
REQUIREMENTS_MODEL_NAME=gemini-2.5-pro
# OpenRouter reasoning toggles (only used when LLM_PROVIDER=openrouter).
QUERY_MODEL_REASONING_ENABLED=false
REQUIREMENTS_MODEL_REASONING_ENABLED=true
# Example OpenRouter model: xiaomi/mimo-v2-flash:free
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

# Path where FAISS artifacts are stored.
VECTOR_STORE_DIR=artifacts/vector_store
