# Copy to .env and replace placeholders before running the pipeline.

# Gemini API key (required).
GEMINI_API_KEY=your-gemini-key

# Optional: forwarded to LangChain if you prefer to keep both keys explicit.
GOOGLE_API_KEY=${GEMINI_API_KEY}

# LLM provider selection: gemini (default) or openrouter.
LLM_PROVIDER=gemini

# OpenRouter API key (required if LLM_PROVIDER=openrouter).
OPENROUTER_API_KEY=your-openrouter-key
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Model overrides (optional; defaults shown here).
QUERY_MODEL_NAME=gemini-2.5-flash
REQUIREMENTS_MODEL_NAME=gemini-2.5-pro
# OpenRouter reasoning toggles (only used when LLM_PROVIDER=openrouter).
QUERY_MODEL_REASONING_ENABLED=false
REQUIREMENTS_MODEL_REASONING_ENABLED=true
# Example OpenRouter model: xiaomi/mimo-v2-flash:free
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

# Path where FAISS artifacts are stored.
VECTOR_STORE_DIR=artifacts/vector_store

# Vector store backend: faiss (default) or milvus.
VECTOR_STORE_BACKEND=faiss

# Milvus connection settings (used when VECTOR_STORE_BACKEND=milvus).
MILVUS_HOST=milvus
MILVUS_PORT=19530
MILVUS_COLLECTION=agenticai_chunks_hybrid
# Optional: use a full URI instead of host/port (overrides host/port when set).
MILVUS_URI=
MILVUS_ENABLE_HYBRID=true

# Hybrid reranker (optional).
RERANKER_ENABLED=false
RERANKER_MODEL_NAME=BAAI/bge-reranker-base
RERANKER_DEVICE=cpu

# Web search controls
WEB_SEARCH_ENABLED=true
WEB_SEARCH_MAX_QUERIES_PER_DOC=3

# Pipeline throttling
PIPELINE_THROTTLE_ENABLED=false

# Evidence distillation batching (0 = disabled)
EVIDENCE_DISTILL_MAX_CHUNKS_PER_BATCH=0
